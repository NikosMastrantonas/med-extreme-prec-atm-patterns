{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (C) Copyright 1996- ECMWF.\n",
    "#\n",
    "# This software is licensed under the terms of the Apache Licence Version 2.0\n",
    "# which can be obtained at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "# In applying this licence, ECMWF does not waive the privileges and immunities\n",
    "# granted to it by virtue of its status as an intergovernmental organisation\n",
    "# nor does it submit to any jurisdiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import multiprocessing\n",
    "import tqdm\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_loc = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = dir_loc + 'ProcessedData/'\n",
    "Path(out_dir).mkdir(parents=True, exist_ok=True) # main directory for saving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the data for Cycle 46r1 (start at 2019-06-11, finish at 2020-06-30)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dates for Cycle 46r1 11 June 2019 - 30 June 2020\n",
    "start_date = '20190611'\n",
    "end_date = '20200630'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialization_dates = pd.date_range(start_date, end_date)\n",
    "\n",
    "# keep Mondays (0) and Thursdays (3)\n",
    "initialization_dates = initialization_dates[(initialization_dates.weekday == 0) | (initialization_dates.weekday == 3)]\n",
    "initialization_dates = initialization_dates.strftime('%Y%m%d')\n",
    "\n",
    "del(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read patterns composites for extracting data about variables and coordinates used\n",
    "Composites = xr.open_dataset(dir_loc+'ProcessedData/PatternComposites_ERA5.nc')\n",
    "Var_used = list(Composites.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frcst_data(input_data):\n",
    "    \n",
    "    ''' Input data is a list of 2 [a., b.] with: a. initialization date, b. parameter used '''\n",
    "    \n",
    "    init_date_used = input_data[0] # initialization date of forecast\n",
    "    param_used = input_data[1] # atmospheric variable of interest\n",
    "    \n",
    "    'Get the reforecast data for the selected initialization date and parameter'\n",
    "    # get the data of the control member (cf)\n",
    "    files_loc = dir_loc+'Data/'+param_used+'/cf/'\n",
    "    file_name = files_loc+param_used+'_cf_'+init_date_used+'.grb'\n",
    "    control_forecast = xr.open_dataarray(file_name, engine='cfgrib')\n",
    "    control_forecast = control_forecast.astype('float32') # float32 for memory efficiency\n",
    "    control_forecast = control_forecast.sel(latitude=Composites.latitude, longitude=Composites.longitude)\n",
    "    control_forecast = control_forecast.assign_coords({'number': 0})\n",
    "    \n",
    "    # get the data of the ensemble members (pf)\n",
    "    files_loc = dir_loc+'Data/'+param_used+'/pf/'\n",
    "    file_name = files_loc+param_used+'_pf_'+init_date_used+'.grb'\n",
    "    ensemble_forecast = xr.open_dataarray(file_name, engine='cfgrib')\n",
    "    ensemble_forecast = ensemble_forecast.astype('float32') # float32 for memory efficiency\n",
    "    ensemble_forecast = ensemble_forecast.sel(latitude=Composites.latitude, longitude=Composites.longitude)\n",
    "    \n",
    "    frcst_data = xr.concat([control_forecast, ensemble_forecast], dim='number') # combine cf and pf data\n",
    "    \n",
    "    all_mean = frcst_data.mean(dim=['number']) # mean of all members (ensemble + control)\n",
    "    all_mean = all_mean.assign_coords({'number':-1}) # assign the mean as \"-1\" on the number coordinate\n",
    "    \n",
    "    final = xr.concat([frcst_data, all_mean], dim='number').sortby('number') # combine frcst data and frcst mean data\n",
    "    \n",
    "    final = final.rolling(step=2).mean().dropna('step') # average start and end of day for getting mean daily field\n",
    "    final = final.assign_coords({'step': final.step.values-np.timedelta64(1, 'D')}) # step is the min possible lag\n",
    "    \n",
    "    final.name = param_used\n",
    "    \n",
    "    return final.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_frst(dates, variable):\n",
    "    \n",
    "    combs = list(product(dates, [variable]))\n",
    "    pool = multiprocessing.Pool() # object for multiprocessing\n",
    "    Data = list(tqdm.tqdm(pool.imap(frcst_data, combs), total=len(combs), position=0, leave=True))\n",
    "    pool.close()\n",
    "    \n",
    "    Data = xr.concat(Data, dim='time')\n",
    "    \n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Frcst = [all_frst(dates=initialization_dates, variable=i_var) for i_var in Var_used]\n",
    "Frcst = xr.merge(Frcst).reset_coords(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate model(lead-time)-dependent climatology\n",
    "members = Frcst.number.values # get flag of the members\n",
    "Frcst_clim = Frcst.sel(number=members[members>=0]) # don't use ensemble mean for deriving the climatology\n",
    "Frcst_clim = Frcst_clim.assign_coords({'time': pd.to_datetime(Frcst_clim.time.values).strftime('%m%d')})\n",
    "Frcst_clim = Frcst_clim.groupby('time').mean()\n",
    "Frcst_clim = Frcst_clim.mean(['number'])\n",
    "del(members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get forecasts anomalies by removing model(lead-time)-dependent climatology\n",
    "dates_actual = Frcst.time.values\n",
    "dates_grouped = pd.to_datetime(dates_actual) # get values of actual valid_time of the forecast\n",
    "Frcst = Frcst.assign_coords({'time': dates_grouped.strftime('%m%d')}) # change the time to Month-Day\n",
    "Anom = Frcst.groupby('time') - Frcst_clim # calculate the final anomalies from ERA5 climatology\n",
    "Anom = Anom.assign_coords({'time': dates_actual}) # change back to initiation date\n",
    "Anom = Anom.assign_coords({'valid_time': Anom.time + Anom.step})\n",
    "\n",
    "del(Frcst, Frcst_clim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " # read mean Euclidian differences of ERA5 for bringing the distances of all variables at same magnitudes\n",
    "ERA5_MeanDifs = xr.open_dataset(dir_loc+'ProcessedData/DifMeanERA5_climatological.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_allocation(i_step):\n",
    "    \n",
    "    Weights = np.cos(np.deg2rad(Composites.latitude))\n",
    "\n",
    "    Difs_all = []\n",
    "    for i in Composites.cluster.values: # use loop, because memory is not enough to perform all difs at once!\n",
    "        Difs = Anom.isel(step=i_step) - Composites.sel(cluster=i) # difference from composite per cell\n",
    "        Difs = Difs**2 # square of differences\n",
    "        Difs = Difs.weighted(Weights).mean(['latitude', 'longitude']) # weighted mean of the differences for all cells\n",
    "        Difs = np.sqrt(Difs) # square root of error (as in RMSE metric)\n",
    "        Difs_all.append(Difs)   \n",
    "\n",
    "    Difs_all = xr.concat(Difs_all, dim=pd.Index(Composites.cluster.values, name='cluster')) # concat results\n",
    "    Difs_all = Difs_all/ERA5_MeanDifs\n",
    "\n",
    "    Difs_all = Difs_all.to_array()\n",
    "    Difs_all = Difs_all.rename({'variable': 'atm_variable'})\n",
    "    Difs_all = Difs_all.mean('atm_variable') # mean of differences for all variables\n",
    "\n",
    "    ClusterAllocation = Difs_all.argmin('cluster')\n",
    "\n",
    "    ClusterAllocation = ClusterAllocation.to_dataframe(name='Cluster') # convert to DF and give the column name\n",
    "    ClusterAllocation = ClusterAllocation.reset_index() # reset so we have all multiindex data as seperate columns\n",
    "    ClusterAllocation['valid_time'] = ClusterAllocation['time']+ClusterAllocation['step'] # correct valid time\n",
    "\n",
    "    ClusterAllocation.step = ClusterAllocation.step.apply(lambda x: x.days) # convert to numeric  \n",
    "    \n",
    "    return ClusterAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Steps_all = np.arange(len(Anom.step.values))\n",
    "pool = multiprocessing.Pool() # object for multiprocessing\n",
    "Alloc = list(tqdm.tqdm(pool.imap(cluster_allocation, Steps_all), total=len(Steps_all), position=0, leave=True))\n",
    "pool.close()\n",
    "Alloc = pd.concat(Alloc) # concatenate results for all lead times (steps)\n",
    "Alloc.sort_values(by=['time', 'step', 'number'], inplace=True) # sort data\n",
    "Alloc.index = range(0, len(Alloc)) # new indexes\n",
    "\n",
    "Alloc.to_csv(out_dir+'ForecastsClusterAllocations.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
