{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (C) Copyright 1996- ECMWF.\n",
    "#\n",
    "# This software is licensed under the terms of the Apache Licence Version 2.0\n",
    "# which can be obtained at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "# In applying this licence, ECMWF does not waive the privileges and immunities\n",
    "# granted to it by virtue of its status as an intergovernmental organisation\n",
    "# nor does it submit to any jurisdiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path # for dictionaries/files\n",
    "\n",
    "# basic libraries for data analysis\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import xarray as xr\n",
    "\n",
    "# plotting functions\n",
    "from matplotlib import rc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# functions/classes used for specific plots\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm # for user-defined colorbars on matplotlib\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid # for multiplots and nice mixing with cartopy\n",
    "from cartopy.mpl.geoaxes import GeoAxes # for adding cartopy attributes to subplots\n",
    "from matplotlib.image import imread\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('font', size=8)\n",
    "rc('axes', labelsize=7, linewidth=0.2)\n",
    "rc('legend', fontsize=6)\n",
    "rc('xtick', labelsize=6)\n",
    "rc('ytick', labelsize=6)\n",
    "rc('lines', lw=0.5, mew=0.4)\n",
    "rc('grid', linewidth=0.2)\n",
    "\n",
    "sns.set_palette('colorblind') # change the default patette to colorblind-friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/ProcessedData/'\n",
    "output_dir = '/PlotsPaper/'\n",
    "\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True) # generate subfolder for storing the results\n",
    "Path(output_dir+'Png/').mkdir(parents=True, exist_ok=True) # generate subfolder for storing png figures\n",
    "Path(output_dir+'Pdf/').mkdir(parents=True, exist_ok=True) # generate subfolder for storing pdf figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions for informative colorbars\n",
    "\n",
    "def plot_discrete_bar_inset(col_lims, col_used, data_used, ax, width, height, xlabel, cat_names, \n",
    "                            col_text='black', alpha_used=1, loc=8, brdpad=-2, bar_text_size=6):\n",
    "    \n",
    "    ' Categorical data: add bar plot as colorbar and include names of classes and percentage of data per class'\n",
    "    \n",
    "    if type(col_text) == str: col_text = [col_text]*len(col_used)\n",
    "    \n",
    "    ax_sub = inset_axes(ax, loc=loc, width=width, height=height, borderpad=brdpad) # create the axes of the bar\n",
    "\n",
    "    Cl = col_lims[::-1] # reverse because barplot starts from largest to smallest\n",
    "    Cu = col_used[::-1] # reverse because barplot starts from largest to smallest\n",
    "\n",
    "    ax_sub.barh(width=Cl-Cl[-1], y=0, height=1, color=Cu, alpha=alpha_used) # plot colored bars\n",
    "    ax_sub.barh(width=Cl[0]-Cl[-1], y=0, height=1,\n",
    "                edgecolor='black', color='none', linewidth=.2, clip_on=False) # transparent bar with black frame\n",
    "\n",
    "    ax_sub.set_xlim(col_lims[0], col_lims[-1]) # change the limits of the plot\n",
    "    ax_sub.set_ylim(-.5, .5) # change so that colorbar covers full plot (colorbar has y=0, and height=1)\n",
    "    ax_sub.set_yticks([]) # remove yticks\n",
    "    \n",
    "    Xticks = pd.Series(col_lims).rolling(2).mean().values[1:] # get position of ticks as middle point of each bar\n",
    "    for i, j in enumerate(cat_names): # inside the bars in the Xticks locations state the provided cat_names\n",
    "        ax_sub.text(s=j, x=Xticks[i], y=0, ha='center', va='center', color=col_text[i], size=bar_text_size)\n",
    "\n",
    "    ax_sub.set_xticks(ticks=Xticks) # add the ticks in the desired locations\n",
    "    ax_sub.set_xticklabels(labels=data_used, fontsize=6) # add the xticks_labels\n",
    "    ax_sub.set_xlabel(xlabel, size=6) # add the final title of the bar as xlabel\n",
    "    ax_sub.xaxis.set_tick_params(width=.2, length=1)\n",
    "    \n",
    "    return ax_sub\n",
    "\n",
    "def plot_continuous_bar_inset(col_lims, col_used, data, ax, width, height, xlabel, loc=8, brdpad=-2):\n",
    "    \n",
    "    ' Continuous data: Add boxplot inside colorbar with the distribution of the studied variable for all the points'\n",
    "    \n",
    "    ax_sub = inset_axes(ax, loc=loc, width=width, height=height, borderpad=brdpad) # create the axes of the bar\n",
    "    \n",
    "    Cl = col_lims[::-1] # reverse because barplot starts from largest to smallest\n",
    "    Cu = col_used[::-1] # reverse because barplot starts from largest to smallest\n",
    "    \n",
    "    ax_sub.barh(width=Cl-Cl[-1], y=0, height=1, left=Cl[-1], color=Cu) # plot colored bars\n",
    "    ax_sub.barh(width=Cl[0]-Cl[-1], y=0, height=1, left=Cl[-1],\n",
    "                edgecolor='black', color='none', linewidth=.2, clip_on=False) # transparent bar with back frame\n",
    "\n",
    "    # plot boxplot of data; use positions=[0], so that the plot aligns with the colorbars\n",
    "    ax_sub.boxplot(data, sym='x', vert=False, widths=.3, positions=[0], capprops={'linewidth': .2}, \n",
    "                    boxprops={'linewidth': .2}, flierprops={'marker': 'x', 'markersize': .3}, \n",
    "                    medianprops={'color': 'black', 'linewidth': .2}, whiskerprops={'linewidth': .2})\n",
    "\n",
    "    ax_sub.set_ylim(-0.5, 0.5) # change so that colorbar covers full plot (colorbar has y=0, and height=1)\n",
    "    ax_sub.set_yticks([]) # remove ticks of y-axis\n",
    "    \n",
    "    ax_sub.set_xlim(col_lims[0], col_lims[-1]) # set limits of x-axis\n",
    "    ax_sub.set_xticks(col_lims) # set ticks of x axis\n",
    "    ax_sub.xaxis.set_tick_params(width=.2, length=1) # change ticks visualization (same width as linewidth of barh)\n",
    "    ax_sub.set_xlabel(xlabel, size=6) # set label of x-axis\n",
    "    \n",
    "    return ax_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary variables for patterns (names, colors, etc)\n",
    "New_names = ['Atlantic Low', 'Biscay Low', 'Iberian Low', 'Sicilian Low', 'Balkan Low', 'Black Sea Low',\n",
    "             'Mediterranean High', 'Minor Low', 'Minor High'] # naming in the final order of interest\n",
    "\n",
    "Cl_cols_used = [(.02, 0.40, 0.55), (.0, 0.75, 0.7), (.0, 0.63, 0.4), (.85, 0.35, 0.1), (.8, 0.5, 0.75), \n",
    "                (.7, 0.5, 0.45), (1, 0.7, 0.75), (.65, 0.65, 0.65), (.95, 0.95, 0.2)] # color for each pattern\n",
    "Cl_vals_used = np.arange(len(Cl_cols_used))\n",
    "\n",
    "# final area used for analysis\n",
    "Area_used = [48, -10, 27, 41]\n",
    "Y_max, X_min, Y_min, X_max = Area_used\n",
    "\n",
    "# areas for subplots of Figures 8 and 10\n",
    "Areas = {'All': [X_min, X_max, Y_min, Y_max], \n",
    "         'Iberia': [-9, -1, 37, 44], 'Northern Morocco': [-7, -4, 34, 36], \n",
    "         'Southern Italy': [15, 18.5, 38, 41], 'Alpes': [8, 13, 45, 46], 'Aegean - Western Turkey': [26, 30, 36, 41]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Composites = xr.open_dataset(input_dir+'PatternComposites_ERA5.nc')\n",
    "Composites = Composites.to_array()\n",
    "Labels = pd.read_csv(input_dir+'PatternAllocations_ERA5.csv', index_col=0)\n",
    "Labels.index = pd.to_datetime(Labels.index)\n",
    "Labels = Labels[Labels.index<=pd.to_datetime('2019-12-31')]['Label'] # only 1979-2019, as in Mastrantonas, et al 2021\n",
    "Climat_Frequencies = Labels.value_counts()/len(Labels)*100\n",
    "Climat_Frequencies = Climat_Frequencies.reindex(range(len(New_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_aux = list(map(chr, range(97, 123)))[:9] # alphabetic order for subplots naming\n",
    "Colors_used = sns.color_palette('RdBu_r', n_colors=15)\n",
    "Colors_used = Colors_used[:5]+['white']+Colors_used[-5:]\n",
    "Colors_used = ListedColormap(Colors_used)\n",
    "Colors_limits = [-16, -13, -10, -7, -4, -1, 1, 4, 7, 10, 13, 16] # levels for the colors (actual abs. max is 15.7)\n",
    "Cont_levels = np.linspace(-24, 24, 13) # act. max is 21.2\n",
    "\n",
    "X, Y = np.meshgrid(Composites.longitude, Composites.latitude)\n",
    "Max_values = np.abs(Composites).max(dim=['cluster', 'latitude', 'longitude']).values\n",
    "Max_values = np.round(Max_values/np.array([100, 98.1]), 2)\n",
    "print('Absolute Max values for SLP and Z500 are {} hPa and {} dam respectively'.format(Max_values[0], Max_values[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes_class = (GeoAxes, dict(map_projection=ccrs.PlateCarree()))\n",
    "fig = plt.figure(figsize=(18/2.54, 9.1/2.54))\n",
    "grid = AxesGrid(fig, 111, nrows_ncols=(3,3), axes_pad=.2,\n",
    "                cbar_mode='single', cbar_location='right', cbar_pad=.1,\n",
    "                axes_class=axes_class, cbar_size='3%', label_mode='')\n",
    "\n",
    "for i, ax in enumerate(grid):\n",
    "\n",
    "    ax.set_extent([X.min(), X.max(), Y.min(), Y.max()], crs=ccrs.PlateCarree()) # set extent\n",
    "    ax.outline_patch.set_linewidth(.2) # reduce the border thickness\n",
    "    \n",
    "    ax.coastlines(resolution='110m', linewidth=.5, color='grey') # add coastline\n",
    "\n",
    "    contf = ax.contourf(X, Y, Composites.sel(variable='SLP', cluster=i)/100, # plot contourf for SLP anomalies\n",
    "                        transform=ccrs.PlateCarree(), levels=Colors_limits, cmap=Colors_used) \n",
    "    cont = ax.contour(X, Y, Composites.sel(variable='Z500', cluster=i)/98.1, # plot contour for Z500 anomalies\n",
    "                      transform=ccrs.PlateCarree(),levels=Cont_levels, colors='black') \n",
    "    ax.clabel(cont, inline=1, fontsize=6, fmt='%d')\n",
    "    for line, lvl in zip(cont.collections, cont.levels):\n",
    "        if lvl == 0:\n",
    "            line.set_linestyle(':')\n",
    "\n",
    "    ax.set_title('({}) Cl. {} - {} ({:.1f}%)'.format(title_aux[i], i+1, New_names[i], Climat_Frequencies[i]), \n",
    "                 pad=4, size=7.5, loc='left')\n",
    "\n",
    "cbar = ax.cax.colorbar(contf, ticks=Colors_limits, spacing='proportional') # add colorbar\n",
    "cbar.ax.set_title(\"SLP' (hPa)\", size=6.5, loc='left')\n",
    "cbar.ax.yaxis.set_tick_params(width=.25, length=3)\n",
    "\n",
    "plt.subplots_adjust(left=0.02, bottom=0.01, right=.95, top=.96)\n",
    "fig.savefig(output_dir+'Pdf/Fig1.pdf')\n",
    "fig.savefig(output_dir+'Png/Fig1.png', dpi=600, transparent=True)\n",
    "\n",
    "del(axes_class, fig, grid, i, ax, contf, cont, line, lvl, cbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(Composites, Labels, Climat_Frequencies, title_aux, Colors_used, Colors_limits, Cont_levels, X, Y, Max_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_all = plt.subplots(1, 1, figsize=(8/2.54, 3.7/2.54), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "\n",
    "ax_all.set_extent([X_min, X_max, Y_min, Y_max], crs=ccrs.PlateCarree())\n",
    "ax_all.outline_patch.set_linewidth(.2) # reduce the border thickness\n",
    "\n",
    "fname = '/Data/HYP_LR_SR_OB_DR.tif' # downloaded from https://www.naturalearthdata.com/downloads/10m-raster-data/10m-cross-blend-hypso/\n",
    "ax_all.imshow(imread(fname), origin='upper', extent=[-180, 180, -90, 90])\n",
    "plt.subplots_adjust(left=0.01, bottom=0.01, right=.99, top=.99)\n",
    "    \n",
    "fig.savefig(output_dir+'Pdf/Fig2.pdf', dpi=1200)\n",
    "fig.savefig(output_dir+'Png/Fig2.png', dpi=1200, transparent=True)\n",
    "\n",
    "del(fig, ax_all, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllTime = input_dir+'ForecastsPatterns/FreqsAll_ERA5.nc'\n",
    "AllTime = xr.open_dataarray(AllTime)\n",
    "ZeroTime = input_dir+'ForecastsPatterns/FreqsAll_ERA5_0UTC.nc'\n",
    "ZeroTime = xr.open_dataarray(ZeroTime)\n",
    "                             \n",
    "UTC = pd.Index([False, True], name='ZeroUTC')\n",
    "FreqsAll = xr.concat([AllTime, ZeroTime], dim=UTC)\n",
    "FreqsAll = FreqsAll.to_dataframe('Freq').reset_index()\n",
    "del(AllTime, ZeroTime, UTC)\n",
    "\n",
    "Freqs = FreqsAll.query('temp_window==0 and ZeroUTC==False') # keep with no temporal window and nly for all hrl data\n",
    "Freqs = Freqs.pivot_table(columns='cluster', index='temp_subset', values='Freq')*100\n",
    "Freqs = Freqs.iloc[:-3, :] # don't use statistics for All, and summer-/winter- half periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices for start and end of Summer Half (Summer Half between 16th April - 15th October, inclusive both dates)\n",
    "Sorted_Dates = np.array(pd.date_range('20040101', '20041231').strftime('%m%d')) # a leap year for getting all dates\n",
    "Freqs.index = pd.Series(Freqs.index).replace({i_d:i for i, i_d in enumerate(Sorted_Dates)})\n",
    "\n",
    "Start_Month = [('0'+str(i))[-2:]+'01' for i in range(1, 13)]\n",
    "start_locs = [np.where(Sorted_Dates==i)[0] for i in Start_Month]\n",
    "start_locs = np.array(start_locs).flatten()\n",
    "\n",
    "end_locs = (start_locs-1)[1:]\n",
    "end_locs = np.insert(end_locs, len(end_locs), len(Sorted_Dates)-1)\n",
    "\n",
    "x_locs = (start_locs+end_locs)/2\n",
    "x_ticks = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, gridspec_kw={'height_ratios': [1, .1]}) \n",
    "ax = ax.flatten()\n",
    "Freqs.iloc[:].plot(kind='bar', stacked=True, figsize=(8/2.54, 5/2.54), width=1, color=Cl_cols_used, ax=ax[0])\n",
    "ax[0].set_ylabel('Frequencies (%)')\n",
    "ax[0].set_ylim(0, 100)\n",
    "ax[0].axvline(np.where(Sorted_Dates=='0415')[0]+.5, color='black', linestyle='--', linewidth=1)\n",
    "ax[0].text(s=16, x=np.where(Sorted_Dates=='0415')[0]+.5, y=0, ha='left', va='bottom', color='white', size=6)\n",
    "ax[0].axvline(np.where(Sorted_Dates=='1016')[0]-.5, color='black', linestyle='--', linewidth=1)\n",
    "ax[0].text(s=15, x=np.where(Sorted_Dates=='1016')[0]-.5, y=0, ha='right', va='bottom', color='white', size=6)\n",
    "h,l = ax[0].get_legend_handles_labels()\n",
    "ax[0].legend(h, New_names, bbox_to_anchor=(.42, -.1), loc='upper center', ncol=3)\n",
    "ax[0].yaxis.set_tick_params(width=.25, length=2) # modify y-axis ticks\n",
    "\n",
    "ax[1].set_ylim(-.5, .5)\n",
    "for i, j in zip(x_locs, x_ticks): # inside the bars in the Xticks locations state the provided cat_names\n",
    "    ax[1].text(s=j, x=i, y=0, ha='center', va='center', color='black', size=7)\n",
    "ax[1].barh(width=len(Freqs), y=0, height=1, color='cyan')\n",
    "ax[1].barh(width=np.where(Sorted_Dates=='1016')[0]-.5 - (np.where(Sorted_Dates=='0415')[0]+.5), \n",
    "           left=np.where(Sorted_Dates=='0415')[0]+.5, y=0, height=1, color='orange')\n",
    "\n",
    "for i_ax in ax:\n",
    "    i_ax.set_xlim(-.5, len(Freqs)-.5)\n",
    "    [i_ax.axvline(i, color='black', linestyle='--', linewidth=0.25) for i in start_locs[1:]]\n",
    "    \n",
    "ax[0].get_xaxis().set_visible(False)\n",
    "ax[1].get_xaxis().set_visible(False)\n",
    "ax[1].get_yaxis().set_visible(False)\n",
    "fig.subplots_adjust(left=0.15, bottom=0.25, right=.97, top=.96, wspace=0, hspace=0) # modify margins of figure\n",
    "\n",
    "fig.savefig(output_dir+'Pdf/Fig3.pdf')\n",
    "fig.savefig(output_dir+'Png/Fig3.png', dpi=600, facecolor=fig.get_facecolor())\n",
    "\n",
    "del(FreqsAll, Freqs, Sorted_Dates, Start_Month, start_locs, end_locs, x_locs, x_ticks, fig, ax, h, l, i, j, i_ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4 (and similar Supplementary ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClustersCondProb = xr.open_dataarray(input_dir+'ForecastsEPEs_Analysis/Connections_Patterns.nc')\n",
    "ClustersCondProb = ClustersCondProb.sel(longitude=slice(Area_used[1], Area_used[3]), \n",
    "                                        latitude=slice(Area_used[0], Area_used[2]))\n",
    "\n",
    "# create auxiliary data for proper plotting based on pcolormesh\n",
    "X, Y = np.meshgrid(ClustersCondProb.longitude, ClustersCondProb.latitude)\n",
    "X_grid2 = np.abs(np.diff(ClustersCondProb.longitude)[0])/2 # when using imshow/pcolor, adjust extend ...\n",
    "Y_grid2 = np.abs(np.diff(ClustersCondProb.latitude)[0])/2 # ... as the coords refer to the center not edges\n",
    "\n",
    "'''\n",
    "It seems that for some reason imshow has a slight shift of the data so the pcolor is used instead.\n",
    "Nevertheless, pcolor defines each location as lower left corner, and does not plot the last column & row, so some\n",
    "auxiliary data need to be created to overcome this issue, and use pcolor for generating accurate figures.\n",
    "Possible explanation of imshow error: https://github.com/matplotlib/matplotlib/issues/12934\n",
    "''' \n",
    "Aux = np.zeros(np.array([len(ClustersCondProb.latitude), len(ClustersCondProb.longitude)])+1) # dimensions of lat/lon\n",
    "\n",
    "X_all = Aux.copy()\n",
    "X_all[:, :-1] = X[0, :]\n",
    "X_all[:, -1] = X.max()+X_grid2*2\n",
    "X_all -= X_grid2 # shift the data so each location refers to the center and not the edge\n",
    "Y_all = Aux.copy()\n",
    "Y_all[1:, :] = Y[:,0][..., np.newaxis]\n",
    "Y_all[0, :] = Y.max()+Y_grid2*2\n",
    "Y_all -= Y_grid2 # shift the data so each location refers to the center and not the edge\n",
    "del(Aux, X_grid2, Y_grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "HighestProbValue = ClustersCondProb.max('cluster')\n",
    "HighestProbValue = (HighestProbValue*100)/(100-HighestProbValue.percentile)\n",
    "HighestProbCluster = ClustersCondProb.argmax('cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fig4_type(perc_used):\n",
    "    \n",
    "    Short_names = ['AtlL', 'BscL', 'IbrL', 'SclL', 'BlkL', 'BlSL', 'MedH', 'MnrL', 'MnrH']\n",
    "    \n",
    "    fig, ax_all = plt.subplots(2, 3, figsize=(18/2.54, 7.5/2.54), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    ax_all = ax_all.flatten()\n",
    "    \n",
    "    temp_subsets = ['All', 'WinterHalf', 'SummerHalf']\n",
    "    title_aux = list(map(chr, range(97, 123)))[:6] # alphabetic order for subplots naming\n",
    "\n",
    "    # get aux. data for the cond. prob. plottings\n",
    "    CondProbMax = HighestProbValue.sel(percentile=perc_used, temporal=temp_subsets).max().values\n",
    "    CondProbMax = int(np.ceil(CondProbMax))\n",
    "    Cond_vals_used = np.arange(0, CondProbMax+1)*(100-perc_used)\n",
    "    Cond_cols_used = sns.color_palette('pink_r', n_colors=len(Cond_vals_used)-1)\n",
    "    \n",
    "    # modifications for having correct \"BoundaryNorm\"\n",
    "    Cl_vals_used_full = np.insert(Cl_vals_used, len(Cl_vals_used), len(Cl_vals_used))\n",
    "    \n",
    "    # plot the best clusters\n",
    "    for i, j in enumerate(temp_subsets):\n",
    "\n",
    "        cluster_data = HighestProbCluster.sel(percentile=perc_used, temporal=j).values\n",
    "        cluster_plot = ax_all[i].pcolor(X_all, Y_all, cluster_data, transform=ccrs.PlateCarree(), \n",
    "                                        norm=BoundaryNorm(Cl_vals_used_full, len(Cl_cols_used)), \n",
    "                                        cmap=ListedColormap(Cl_cols_used))\n",
    "\n",
    "        ax_all[i].text(0.5, 1.1, f\"{['Year-round', 'WinterHalf', 'SummerHalf'][i]} statistics\", fontsize=8.5, \n",
    "                       ha='center', transform = ax_all[i].transAxes)\n",
    "\n",
    "        # add informative colorbar\n",
    "        Counts = pd.Series(cluster_data.flatten()).value_counts()\n",
    "        Counts = Counts.reindex(Cl_vals_used).fillna(0)\n",
    "        Counts = np.round(Counts/cluster_data.size*100, 1).astype(str)\n",
    "        plot_discrete_bar_inset(col_lims=Cl_vals_used_full, col_used=Cl_cols_used, data_used=Counts, \n",
    "                                ax=ax_all[i], brdpad=-2, loc=8, cat_names=Short_names, col_text='black',\n",
    "                                width='100%', height='15%', xlabel='Percentage of grid cells (%)')\n",
    "\n",
    "\n",
    "    # plot conditional probabilities of the best 2 clusters\n",
    "    for i, j in zip([3,4,5], temp_subsets):\n",
    "\n",
    "        cond_data = HighestProbValue.sel(percentile=perc_used, temporal=j).values\n",
    "        cond_data = cond_data*(100-perc_used)\n",
    "        cond_plot = ax_all[i].pcolor(X_all, Y_all, cond_data, transform=ccrs.PlateCarree(),\n",
    "                                     norm=BoundaryNorm(Cond_vals_used, len(Cond_cols_used)),\n",
    "                                     cmap=ListedColormap(Cond_cols_used)) \n",
    "        \n",
    "        # add informative colorbar\n",
    "        cond_values = cond_data.flatten()\n",
    "        plot_continuous_bar_inset(col_lims=Cond_vals_used, col_used=Cond_cols_used, data=cond_values, ax=ax_all[i], \n",
    "                                  width='100%', height='15%', loc=8, brdpad=-2, xlabel='Conditional Probability (%)')\n",
    "\n",
    "    ax_all[0].text(-.07, .5, 'Cluster of MCP', fontsize=8.5, ha='center', va='center',\n",
    "                   transform = ax_all[0].transAxes, rotation=90)\n",
    "    ax_all[3].text(-.07, .5, 'MCP', fontsize=8.5, ha='center', va='center', \n",
    "                   transform = ax_all[3].transAxes, rotation=90)\n",
    "\n",
    "    for i_ax, ax in enumerate(ax_all): # set for all subplots the cartopy map and the extent\n",
    "        ax.text(0.02, 0.96, f'({title_aux[i_ax]})', fontsize=6, ha='left', va='top', color='black',\n",
    "                transform = ax_all[i_ax].transAxes, bbox=dict(facecolor='white', edgecolor='none', alpha=0.5, pad=1))\n",
    "        ax.coastlines(resolution='110m', linewidth=.5, color='black')\n",
    "        ax.outline_patch.set_linewidth(.2) # reduce the border thickness\n",
    "        ax.set_extent([X_min, X_max, Y_min, Y_max], crs=ccrs.PlateCarree())\n",
    "        \n",
    "    plt.subplots_adjust(left=0.05, bottom=0.12, right=.98, top=.95, hspace=.4, wspace=0.1)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_perc in [90, 95, 99]:\n",
    "    Fig4 = Fig4_type(perc_used=i_perc)\n",
    "    Fig4.savefig(output_dir+f'Pdf/Fig4_{i_perc}.pdf')\n",
    "    Fig4.savefig(output_dir+f'Png/Fig4_{i_perc}.png', dpi=600, facecolor=Fig4.get_facecolor())\n",
    "    if i_perc!=95: plt.close()\n",
    "    \n",
    "del(i_perc, Fig4, ClustersCondProb, X, Y, X_all, Y_all, HighestProbValue, HighestProbCluster, Fig4_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5 (and similar Supplementary ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS_all = xr.open_dataset(input_dir+'ForecastsEPEs_Analysis/BS_ERA5_All.nc')\n",
    "BS_all = BS_all.sel(longitude=slice(Area_used[1], Area_used[3]), latitude=slice(Area_used[0], Area_used[2]))\n",
    "\n",
    "BSS_all = BS_all['BSS']\n",
    "BSS_all = BSS_all.where(BSS_all>0)\n",
    "\n",
    "# create auxiliary data for proper plotting based on pcolormesh\n",
    "X, Y = np.meshgrid(BS_all.longitude, BS_all.latitude)\n",
    "X_grid2 = np.abs(np.diff(BS_all.longitude)[0])/2 # when using imshow/pcolor, adjust extend as the coords ...\n",
    "Y_grid2 = np.abs(np.diff(BS_all.latitude)[0])/2 # ... refer to the center of each cell not its edges\n",
    "\n",
    "'''\n",
    "It seems that for some reason imshow has a slight shift of the data so the pcolor is used instead.\n",
    "Nevertheless, pcolor defines each location as lower left corner, and does not plot the last column & row, so some\n",
    "auxiliary data need to be created to overcome this issue, and use pcolor for generating accurate figures.\n",
    "Possible explanation of imshow error: https://github.com/matplotlib/matplotlib/issues/12934\n",
    "''' \n",
    "Aux = np.zeros(np.array(BSS_all.shape[-2:])+1) # dimensions of lat/lon\n",
    "\n",
    "X_all = Aux.copy()\n",
    "X_all[:, :-1] = X[0, :]\n",
    "X_all[:, -1] = X.max()+X_grid2*2\n",
    "X_all -= X_grid2 # shift the data so each location refers to the center and not the edge\n",
    "Y_all = Aux.copy()\n",
    "Y_all[1:, :] = Y[:,0][..., np.newaxis]\n",
    "Y_all[0, :] = Y.max()+Y_grid2*2\n",
    "Y_all -= Y_grid2 # shift the data so each location refers to the center and not the edge\n",
    "del(Aux, X_grid2, Y_grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fig5_type(perc_used=95):\n",
    "    \n",
    "    Plot_used = BSS_all.sel(percentile=perc_used, Method=['All_Patt', 'HalfYear_Patt'])\n",
    "    \n",
    "    Plot_used = Plot_used*100 # make the results as %\n",
    "    Max_value = Plot_used.max().values\n",
    "    Max_value = np.ceil(Max_value)\n",
    "\n",
    "    Cols_used = sns.color_palette('viridis', n_colors=10)\n",
    "    Vals_used = np.linspace(0, Max_value, 11)\n",
    "    \n",
    "    fig, ax_all = plt.subplots(1, 2, figsize=(18/2.54, 6/2.54), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    ax_all = ax_all.flatten()\n",
    "    for i, ax in enumerate(ax_all): # set for all subplots the cartopy map and the extent\n",
    "        ax.coastlines(resolution='110m', linewidth=.5, color='black')\n",
    "        ax.outline_patch.set_linewidth(.2) # reduce the border thickness\n",
    "        ax.set_extent([X_min, X_max, Y_min, Y_max], crs=ccrs.PlateCarree())\n",
    "        \n",
    "        data_mesh = Plot_used.isel(Method=i).values\n",
    "        bss_plot = ax.pcolor(X_all, Y_all, data_mesh, transform=ccrs.PlateCarree(), \n",
    "                             norm=BoundaryNorm(Vals_used, len(Cols_used)), cmap=ListedColormap(Cols_used))\n",
    "\n",
    "        OutperformsLocs = np.isnan(data_mesh).sum()\n",
    "        OutperformsLocs = (data_mesh.size-OutperformsLocs)/data_mesh.size*100 # number of significant locations\n",
    "        OutperformsLocs = np.round(OutperformsLocs, 2) # % locs that cluster is significant\n",
    "        \n",
    "        i_title = ['(a) Year-round Cond. Prob.', '(b) Half-year Cond. Prob.'][i]       \n",
    "        ax.set_title('{}: outperforms in {}% of cells'.format(i_title, OutperformsLocs), \n",
    "                     pad=4, size=8, loc='left')\n",
    "\n",
    "        # add informative colorbar\n",
    "        values_used = data_mesh.flatten()[~np.isnan(data_mesh.flatten())] # only outperforming values\n",
    "        plot_continuous_bar_inset(col_lims=Vals_used, col_used=Cols_used, data=values_used, ax=ax, \n",
    "                                  width='100%', height='15%', loc=8, brdpad=-3, xlabel='BSS (%)')\n",
    "\n",
    "    plt.subplots_adjust(left=0.02, bottom=0.11, right=.98, top=1, hspace=.0, wspace=0.1)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_perc in [90, 95, 99]:\n",
    "    Fig5 = Fig5_type(perc_used=i_perc)\n",
    "    Fig5.savefig(output_dir+f'Pdf/Fig5_{i_perc}.pdf')\n",
    "    Fig5.savefig(output_dir+f'Png/Fig5_{i_perc}.png', dpi=600, facecolor=Fig5.get_facecolor())\n",
    "    if i_perc!=95: plt.close()\n",
    "    \n",
    "del(i_perc, Fig5, BS_all, BSS_all, X, Y, X_all, Y_all, Fig5_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllTime = input_dir+'ForecastsPatterns/BS_Clusters.nc'\n",
    "AllTime = xr.open_dataset(AllTime)\n",
    "ZeroTime = input_dir+'ForecastsPatterns/BS_Clusters_0UTC.nc'\n",
    "ZeroTime = xr.open_dataset(ZeroTime)\n",
    "\n",
    "UTC = pd.Index([False, True], name='ZeroUTC')\n",
    "BS_PatternsAll = xr.concat([AllTime, ZeroTime], dim=UTC)\n",
    "\n",
    "# add np.nan for 0 lead-time, else pointplot shifts data cause it is for categorical so does not know actual location\n",
    "BS_PatternsAll_aux = BS_PatternsAll.sel(Lead_days=1)*np.nan\n",
    "BS_PatternsAll_aux = BS_PatternsAll_aux.assign_coords({'Lead_days': 0})\n",
    "BS_PatternsAll = xr.concat([BS_PatternsAll_aux, BS_PatternsAll], dim='Lead_days')\n",
    "\n",
    "BS_PatternsAll = BS_PatternsAll.to_dataframe().reset_index()\n",
    "BS_PatternsAll['BSS_Masked'] = BS_PatternsAll.BSS.mask(BS_PatternsAll.Sign<=.90) # 90% CI for sign on BSS\n",
    "BS_PatternsAll = BS_PatternsAll.query(\"Method=='Cluster' and Flex_win==0 and bootstrap=='P50'\")\n",
    "del(UTC, AllTime, ZeroTime, BS_PatternsAll_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fig6_type(zero_utc=False):\n",
    "    \n",
    "    BS_Patterns = BS_PatternsAll.query('ZeroUTC==@zero_utc')\n",
    "    \n",
    "    Y_max = np.ceil(BS_Patterns.BSS.max()*10)/10\n",
    "    Y_min = np.floor(BS_Patterns.BSS.min()*10)/10\n",
    "    Markers = ['o', 'v', '^', '<', '>', 's', 'p', '*', 'X']\n",
    "    fig, ax_all = plt.subplots(2, 2, figsize=(18/2.54, 11/2.54))\n",
    "    ax_all = ax_all.flatten()\n",
    "    for i, i_seas in zip([0, 2, 3], ['All', 'WinterHalf', 'SummerHalf']):\n",
    "        sns.lineplot(data=BS_Patterns.query('Season==@i_seas'), x='Lead_days', y='BSS', \n",
    "                     hue='Cluster', linewidth=3, palette=Cl_cols_used, alpha=.15, ax=ax_all[i])\n",
    "        sns.pointplot(data=BS_Patterns.query('Season==@i_seas'), x='Lead_days', y='BSS_Masked',\n",
    "                      hue='Cluster', linewith=4, palette=Cl_cols_used, alpha=1, markers=Markers, ax=ax_all[i])\n",
    "        [i_col.set_sizes([20]) for i_col in ax_all[i].collections]\n",
    "        \n",
    "        ax_all[i].axhline(0, linestyle='--', color='black')\n",
    "        ax_all[i].legend().remove()\n",
    "        ax_all[i].set_xlim(0, 27)\n",
    "        ax_all[i].set_xticks(np.arange(0, 28, 3))\n",
    "        ax_all[i].set_xticklabels(np.arange(0, 28, 3))\n",
    "        \n",
    "        ax_all[i].set_xlabel('Lead days')\n",
    "        ax_all[i].set_ylim(Y_min, Y_max)\n",
    "        ax_all[i].set_ylabel('BSS')\n",
    "        if i_seas == 'All': i_seas = 'Year-round'\n",
    "        ax_all[i].set_title(f\"({['a', 'a', 'b', 'c'][i]}) {i_seas}\", pad=4, loc='left', size=9)\n",
    "        ax_all[i].xaxis.set_tick_params(width=.25, length=2) # modify x-axis ticks\n",
    "        ax_all[i].yaxis.set_tick_params(width=.25, length=2) # modify y-axis ticks\n",
    "\n",
    "    # plot only legend on the upper right plot\n",
    "    mark = []\n",
    "    for i in range(len(New_names)):\n",
    "        mark_i,  = ax_all[1].plot([1, 3], [2, 4], lw=2, marker=Markers[i], color=Cl_cols_used[i], alpha=0)\n",
    "        mark.append(mark_i)\n",
    "\n",
    "    leg = ax_all[1].legend(mark, New_names, loc=10)  \n",
    "    fr = leg.get_frame() # get legend frame\n",
    "    fr.set_lw(0) # modify frame's thickness\n",
    "    for i, l in enumerate(leg.get_lines()):\n",
    "        l.set_alpha(1)\n",
    "        l.set_marker(Markers[i])\n",
    "    [ ax_all[1].spines[i].set_visible(False) for i in ['top', 'right', 'bottom', 'left'] ]\n",
    "    ax_all[1].set_xticks([])\n",
    "    ax_all[1].set_yticks([]) \n",
    "\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=.99, top=.95, wspace=0.25, hspace=0.45)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_zero_utc in [False, True]:\n",
    "    Fig6 = Fig6_type(zero_utc=i_zero_utc)\n",
    "    Fig6.savefig(output_dir+f'Pdf/Fig6_0UTC_{i_zero_utc}.pdf')\n",
    "    Fig6.savefig(output_dir+f'Png/Fig6_0UTC_{i_zero_utc}.png', dpi=600, facecolor=Fig6.get_facecolor())\n",
    "    if i_zero_utc!=False: plt.close()\n",
    "    \n",
    "del(i_zero_utc, Fig6, Fig6_type, BS_PatternsAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllTime = input_dir+'ForecastsPatterns/Decomp_Aggr.nc'\n",
    "AllTime = xr.open_dataset(AllTime)\n",
    "ZeroTime = input_dir+'ForecastsPatterns/Decomp_Aggr_0UTC.nc'\n",
    "ZeroTime = xr.open_dataset(ZeroTime)\n",
    "\n",
    "UTC = pd.Index([False, True], name='ZeroUTC')\n",
    "DecompositionAll = xr.concat([AllTime, ZeroTime], dim=UTC).to_array()\n",
    "\n",
    "DecompositionAll = DecompositionAll.sel(Flex_win=0).reset_coords(drop=True)\n",
    "DecompositionAll = DecompositionAll.to_dataframe('Value').reset_index()\n",
    "del(UTC, AllTime, ZeroTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FigS5_type(zero_utc=False):\n",
    "\n",
    "    Decomposition = DecompositionAll.query('ZeroUTC==@zero_utc')\n",
    "    \n",
    "    fig, ax_all = plt.subplots(3, 3, figsize=(18/2.54, 12.5/2.54))\n",
    "    ax_all = ax_all.flatten()\n",
    "    for i, i_season in enumerate(['All', 'WinterHalf', 'SummerHalf']):\n",
    "        i_p = sns.lineplot(data=Decomposition.query('bootstrap==\"P50\" and Season==@i_season and Stat==\"Res.\"'), \n",
    "                           alpha=.6, x='Lead_days', y='Value', hue='Cluster', palette=Cl_cols_used, \n",
    "                           linewidth=2, ax=ax_all[i])\n",
    "\n",
    "\n",
    "    for i, i_season in enumerate(['All', 'WinterHalf', 'SummerHalf']):\n",
    "        i_p = sns.lineplot(data=Decomposition.query('bootstrap==\"P50\" and Season==@i_season and Stat==\"Rel.\"'), \n",
    "                           alpha=.6, x='Lead_days', y='Value', hue='Cluster', palette=Cl_cols_used, \n",
    "                           linewidth=2, ax=ax_all[i+3])\n",
    "\n",
    "    for i, i_season in enumerate(['All', 'WinterHalf', 'SummerHalf']):\n",
    "        i_p = sns.lineplot(data=Decomposition.query('bootstrap==\"P50\" and Season==@i_season and Stat==\"Unc.\"'), \n",
    "                           alpha=.6, x='Lead_days', y='Value', hue='Cluster', palette=Cl_cols_used, \n",
    "                           linewidth=2, ax=ax_all[i+6])\n",
    "\n",
    "    for i, ax in enumerate(ax_all):\n",
    "        if i == 0: h, l = ax.get_legend_handles_labels()\n",
    "        ax.legend().remove()\n",
    "        ax.set_xlim(0, 45)\n",
    "        ax.set_xticks(np.arange(0, 46, 5))\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_xlabel('Lead days')\n",
    "        ax.xaxis.set_tick_params(width=.25, length=2) # modify x-axis ticks\n",
    "        ax.yaxis.set_tick_params(width=.25, length=2) # modify y-axis ticks\n",
    "\n",
    "        ax.text(0.02, 0.98, f\"({['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i'][i]})\", fontsize=6, ha='left', va='top',\n",
    "                  color='black', transform = ax.transAxes, \n",
    "                  bbox=dict(facecolor='white', edgecolor='none', alpha=0.5, pad=1))\n",
    "        if i <= 2:\n",
    "            ax.text(0.5, 1.1, ['Year-round', 'WinterHalf', 'SummerHalf'][i], fontsize=8, \n",
    "                    ha='center', va='center', transform = ax.transAxes)\n",
    "\n",
    "        if i in [0, 3, 6]:\n",
    "            ax.text(-.3, .5, ['Resolution', '', '', 'Reliability', '', '', 'Uncertainty'][i], fontsize=8, \n",
    "                    ha='center', va='center', transform = ax.transAxes, rotation=90)\n",
    "\n",
    "    [i_h.set_linewidth(2) for i_h in h]\n",
    "    l = New_names  \n",
    "    fig.legend(h, l, ncol=len(New_names)//2+1, loc='lower center', bbox_to_anchor=[0.5, 0.0])\n",
    "    plt.subplots_adjust(left=0.09, bottom=0.18, right=.99, top=.93, wspace=0.25, hspace=0.4)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_zero_utc in [False, True]:\n",
    "    FigS5 = FigS5_type(zero_utc=i_zero_utc)\n",
    "    FigS5.savefig(output_dir+f'Pdf/FigS5_0UTC_{i_zero_utc}.pdf')\n",
    "    FigS5.savefig(output_dir+f'Png/FigS5_0UTC_{i_zero_utc}.png', dpi=600, facecolor=FigS5.get_facecolor())\n",
    "    if i_zero_utc!=False: plt.close()\n",
    "    \n",
    "del(i_zero_utc, FigS5, FigS5_type, DecompositionAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllTime = input_dir+'ForecastsPatterns/FreqOccur_Forecasts.nc'\n",
    "AllTime = xr.open_dataset(AllTime)\n",
    "ZeroTime = input_dir+'ForecastsPatterns/FreqOccur_Forecasts_0UTC.nc'\n",
    "ZeroTime = xr.open_dataset(ZeroTime)\n",
    "\n",
    "UTC = pd.Index([False, True], name='ZeroUTC')\n",
    "FreqBiasesAll = xr.concat([AllTime, ZeroTime], dim=UTC)\n",
    "\n",
    "# add np.nan for 0 lead-time, else pointplot shifts data cause it is for categorical so does not know actual location\n",
    "FreqBiasesAll_aux = FreqBiasesAll.sel(Lead_days=1)*np.nan\n",
    "FreqBiasesAll_aux = FreqBiasesAll_aux.assign_coords({'Lead_days': 0})\n",
    "FreqBiasesAll = xr.concat([FreqBiasesAll_aux, FreqBiasesAll], dim='Lead_days')\n",
    "\n",
    "# add difference of biases when using all timesteps for deriving the ERA5 patterns, and only 0UTC timesteps\n",
    "FreqBiasesAllDifs = np.abs(FreqBiasesAll.sel(ZeroUTC=False)) - np.abs(FreqBiasesAll.sel(ZeroUTC=True))\n",
    "FreqBiasesAllDifs = FreqBiasesAllDifs.assign_coords({'ZeroUTC': 'Dif'})\n",
    "FreqBiasesAll = xr.concat([FreqBiasesAll, FreqBiasesAllDifs], dim='ZeroUTC')\n",
    "\n",
    "FreqBiasesAll = FreqBiasesAll.sel(Flex_win=0, Member='Reforecasts', bootstrap='BS_Median')\n",
    "FreqBiasesAll = FreqBiasesAll.to_dataframe().reset_index()\n",
    "\n",
    "FreqBiasesAll['FreqBiasMasked'] = FreqBiasesAll.FreqBias\n",
    "FreqBiasesAll.loc[FreqBiasesAll.SignDeviations==False, 'FreqBiasMasked'] = np.nan\n",
    "FreqBiasesAll.Cluster = FreqBiasesAll.Cluster.map({i:j for i, j in enumerate(New_names)})\n",
    "del(UTC, AllTime, ZeroTime, FreqBiasesAll_aux, FreqBiasesAllDifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fig7_type(zero_utc=False):\n",
    "    \n",
    "    FreqBiases = FreqBiasesAll.query('ZeroUTC==@zero_utc')\n",
    "    Y_max = np.ceil(np.abs(FreqBiases.FreqBias).max()/10)*10\n",
    "    Markers = ['o', 'v', '^', '<', '>', 's', 'p', '*', 'X']\n",
    "    fig, ax_all = plt.subplots(2, 2, figsize=(18/2.54, 11/2.54))\n",
    "    ax_all = ax_all.flatten()\n",
    "    for i, i_seas in zip([0, 2, 3], ['All', 'WinterHalf', 'SummerHalf']):\n",
    "        sns.lineplot(data=FreqBiases.query('Season==@i_seas'), x='Lead_days', y='FreqBias', hue='Cluster',\n",
    "                     linewidth=2, palette=Cl_cols_used, alpha=.15, ax=ax_all[i])\n",
    "        sns.pointplot(data=FreqBiases.query('Season==@i_seas'), x='Lead_days', y='FreqBiasMasked', hue='Cluster',\n",
    "                      scale=1.5, palette=Cl_cols_used, alpha=1, markers=Markers, ax=ax_all[i])\n",
    "        [i_col.set_sizes([20]) for i_col in ax_all[i].collections]\n",
    "        ax_all[i].axhline(0, linestyle='--', color='black')\n",
    "        ax_all[i].legend().remove()\n",
    "        ax_all[i].set_xlim(0, 45)\n",
    "        ax_all[i].set_xticks(np.arange(0, 46, 5))\n",
    "        ax_all[i].set_xticklabels(np.arange(0, 46, 5))\n",
    "        ax_all[i].set_xlabel('Lead days')\n",
    "        ax_all[i].set_ylim(-Y_max, Y_max)\n",
    "        ax_all[i].set_ylabel('Relative Bias (%)')\n",
    "        if i_seas == 'All': i_seas = 'Year-round'\n",
    "        ax_all[i].set_title(f\"({['a', 'a', 'b', 'c'][i]}) {i_seas}\", pad=4, loc='left', size=9)\n",
    "        ax_all[i].xaxis.set_tick_params(width=.25, length=2) # modify x-axis ticks\n",
    "        ax_all[i].yaxis.set_tick_params(width=.25, length=2) # modify y-axis ticks\n",
    "\n",
    "    # plot only legend on the upper right plot\n",
    "    mark = []\n",
    "    for i in range(len(New_names)):\n",
    "        mark_i,  = ax_all[1].plot([1, 3], [2, 4], lw=2, marker=Markers[i], color=Cl_cols_used[i], alpha=0)\n",
    "        mark.append(mark_i)\n",
    "\n",
    "    leg = ax_all[1].legend(mark, New_names, loc=10)  \n",
    "    fr = leg.get_frame() # get legend frame\n",
    "    fr.set_lw(0) # modify frame's thickness\n",
    "    for i, l in enumerate(leg.get_lines()):\n",
    "        l.set_alpha(1)\n",
    "        l.set_marker(Markers[i])\n",
    "    [ ax_all[1].spines[i].set_visible(False) for i in ['top', 'right', 'bottom', 'left'] ]\n",
    "    ax_all[1].set_xticks([])\n",
    "    ax_all[1].set_yticks([]) \n",
    "\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=.99, top=.95, wspace=0.25, hspace=0.45)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_zero_utc in [False, True, 'Dif']:\n",
    "    Fig7 = Fig7_type(zero_utc=i_zero_utc)\n",
    "    Fig7.savefig(output_dir+f'Pdf/Fig7_0UTC_{i_zero_utc}.pdf')\n",
    "    Fig7.savefig(output_dir+f'Png/Fig7_0UTC_{i_zero_utc}.png', dpi=600, facecolor=Fig7.get_facecolor())\n",
    "    if i_zero_utc!=False: plt.close()\n",
    "    \n",
    "del(i_zero_utc, Fig7, Fig7_type, FreqBiasesAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 8 & Figure 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batlow colorbar from https://www.fabiocrameri.ch/batlow/\n",
    "btlw = ['#011959', '#103F60', '#1C5A62', '#3C6D56', '#687B3E', '#9D892B', '#D29343', '#F8A17B', '#FDB7BC', '#FACCFA']\n",
    "Cols_used = btlw[::-1][2:]\n",
    "Vals_used_general = np.array([0, 3, 5, 7, 9, 11, 13, 15, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BS_EPEs = xr.open_dataset(input_dir+f'ForecastsEPEs_Analysis/BS_leaddays.nc')\n",
    "Weights = np.cos(np.radians(BS_EPEs.latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auxiliary data for proper plotting based on pcolormesh\n",
    "X, Y = np.meshgrid(BS_EPEs.longitude, BS_EPEs.latitude)\n",
    "X_grid2 = np.abs(np.diff(BS_EPEs.longitude)[0])/2 # when using imshow/pcolor, adjust extend as the coords ...\n",
    "Y_grid2 = np.abs(np.diff(BS_EPEs.latitude)[0])/2 # ... refer to the center of each cell not its edges\n",
    "\n",
    "'''\n",
    "It seems that for some reason imshow has a slight shift of the data so the pcolor is used instead.\n",
    "Nevertheless, pcolor defines each location as lower left corner, and does not plot the last column & row, so some\n",
    "auxiliary data need to be created to overcome this issue, and use pcolor for generating accurate figures.\n",
    "Possible explanation of imshow error: https://github.com/matplotlib/matplotlib/issues/12934\n",
    "''' \n",
    "Aux = np.zeros(np.array([len(BS_EPEs['BS'].latitude), len(BS_EPEs['BS'].longitude)])+1) # dimensions of lat/lon\n",
    "\n",
    "X_all = Aux.copy()\n",
    "X_all[:, :-1] = X[0, :]\n",
    "X_all[:, -1] = X.max()+X_grid2*2\n",
    "X_all -= X_grid2 # shift the data so each location refers to the center and not the edge\n",
    "Y_all = Aux.copy()\n",
    "Y_all[1:, :] = Y[:,0][..., np.newaxis]\n",
    "Y_all[0, :] = Y.max()+Y_grid2*2\n",
    "Y_all -= Y_grid2 # shift the data so each location refers to the center and not the edge\n",
    "del(Aux, X_grid2, Y_grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregated_stats(input_data, input_coords):\n",
    "    x_min, x_max, y_min, y_max = input_coords\n",
    "    data = input_data.sel(latitude=slice(y_max, y_min), longitude=slice(x_min, x_max))\n",
    "    data = data.weighted(Weights).mean(['latitude', 'longitude'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AggregatedData = [aggregated_stats(BS_EPEs, i_val) for i_val in Areas.values()]\n",
    "AggregatedData = xr.concat(AggregatedData, dim=pd.Index(list(Areas.keys()), name='Area'))\n",
    "Aggregated = AggregatedData.sel(bootstraps_frcst='P50').to_dataframe().reset_index()\n",
    "Aggregated = Aggregated.query('Method in [\"EPEs_Direct\", \"HalfYear_Patt\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fig8_type(perc_used=95):\n",
    "    \n",
    "    Y_max = np.ceil(Aggregated.BSS.max()*10)/10\n",
    "    Y_min = np.floor(Aggregated.BSS.min()*10)/10\n",
    "    \n",
    "    fig, ax_all = plt.subplots(2, 3, figsize=(18/2.54, 9/2.54))\n",
    "    ax_all = ax_all.flatten()\n",
    "    \n",
    "    for i, i_area in enumerate(Areas):\n",
    "        sns.lineplot(data=Aggregated.query('percentile==@perc_used and Area==@i_area'), x='leaddays', y='BSS', \n",
    "                     hue='Method', linewidth=2, alpha=.3, ax=ax_all[i], hue_order=Aggregated.Method.unique())\n",
    "        sns.lineplot(data=Aggregated.query('percentile==@perc_used and Area==@i_area and BSS>0'), x='leaddays', \n",
    "                     y='BSS', hue='Method', linewidth=3, ax=ax_all[i], hue_order=Aggregated.Method.unique())\n",
    "        ax_all[i].axhline(0, linestyle='--', color='black')\n",
    "        if i!=0: ax_all[i].legend().remove()\n",
    "\n",
    "        ax_all[i].set_xlabel('Lead days')\n",
    "        ax_all[i].set_ylim(Y_min, Y_max)\n",
    "        ax_all[i].set_ylabel('BSS')\n",
    "        ax_all[i].set_title(f\"({['a', 'b', 'c', 'd', 'e', 'f'][i]}) {i_area}\", pad=4, loc='left', size=8)\n",
    "        ax_all[i].xaxis.set_tick_params(width=.25, length=2) # modify x-axis ticks\n",
    "        ax_all[i].yaxis.set_tick_params(width=.25, length=2) # modify y-axis ticks\n",
    "        ax_all[i].set_xlim(0, 45)\n",
    "        ax_all[i].set_xticks(np.arange(0, 46, 5))\n",
    "        ax_all[i].set_xticklabels(np.arange(0, 46, 5))\n",
    "        \n",
    "        if i>0:\n",
    "            ax_sub = inset_axes(ax_all[i], loc=1, width='60%', height='40%', #bbox_to_anchor=(0, 1, 1, 1),\n",
    "                                axes_class=cartopy.mpl.geoaxes.GeoAxes, \n",
    "                                axes_kwargs=dict(map_projection=ccrs.PlateCarree()))\n",
    "            ax_sub.coastlines(resolution='110m', linewidth=.5, color='black')\n",
    "            ax_sub.set_extent([X.min(), X.max(), Y.min(), Y.max()], crs=ccrs.PlateCarree())\n",
    "            x_min, x_max, y_min, y_max = Areas[i_area]\n",
    "            rect = plt.Rectangle((x_min, y_min),x_max-x_min, y_max-y_min, fill=False, color='red', linewidth=.75) \n",
    "            ax_sub.add_patch(rect) # add rectangle with the actual area used for the Precipitation analysis\n",
    "\n",
    "    # plot only the legend\n",
    "    sns.lineplot(data=Aggregated.query('percentile==@perc_used and Area==@i_area'), x='leaddays', y='BSS', \n",
    "                 hue='Method', linewidth=2, alpha=0, ax=ax_all[0], hue_order=Aggregated.Method.unique())\n",
    "    ax_all[0].set_xlabel('Lead days')\n",
    "    ax_all[0].set_ylim(Y_min, Y_max)\n",
    "        \n",
    "    h, l = ax_all[0].get_legend_handles_labels()\n",
    "    l = ['Direct', 'Indirect']\n",
    "    leg = ax_all[0].legend(h, l)\n",
    "    [line.set_linewidth(2) for line in leg.get_lines()]\n",
    "    \n",
    "    plt.subplots_adjust(left=0.07, bottom=0.12, right=.99, top=.93, wspace=0.3, hspace=0.5)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_perc in AggregatedData.percentile.values:\n",
    "    Fig8 = Fig8_type(perc_used=i_perc)\n",
    "    Fig8.savefig(output_dir+f'Pdf/Fig8_{i_perc}.pdf')\n",
    "    Fig8.savefig(output_dir+f'Png/Fig8_{i_perc}.png', dpi=600, facecolor=Fig8.get_facecolor())\n",
    "    if i_perc!=95: plt.close()\n",
    "    \n",
    "del(i_perc, Fig8, Fig8_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/33893692/ @Divakar\n",
    "# https://stackoverflow.com/questions/61339393/numpy-forward-fill-with-condition\n",
    "def numpy_binary_closing(mask,W_gap):\n",
    "    \n",
    "    W = W_gap+1\n",
    "    # Define kernel\n",
    "    K = np.ones(W)\n",
    "\n",
    "    # Perform dilation and threshold at 1\n",
    "    dil = np.convolve(mask,K)>=1\n",
    "\n",
    "    # Perform erosion on the dilated mask array and threshold at given threshold\n",
    "    dil_erd = np.convolve(dil,K)>= W\n",
    "    return dil_erd[W-1:-W+1]\n",
    "\n",
    "def ffill_windowed(a, W_gap):\n",
    "    if W_gap>0:\n",
    "        mask = ~np.isnan(a)\n",
    "        mask_ext = numpy_binary_closing(mask,W_gap)\n",
    "\n",
    "        p = mask_ext & ~mask\n",
    "        idx = np.maximum.accumulate(mask*np.arange(len(mask)))\n",
    "        out = a.copy()\n",
    "        out[p] = out[idx[p]]\n",
    "    else:\n",
    "        out = a\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a mask for the indirect forecast, based on the boostrap data of perfect knowledge of the patterns\n",
    "BSS_Ref_Mask_PerfectForecast = BS_EPEs['Sign_Ref'].sel(Method='HalfYear_Patt_Perfect').mean('leaddays')>.9 \n",
    "BSS_Ref_Mask_PerfectForecast = BSS_Ref_Mask_PerfectForecast.reset_coords(drop=True)\n",
    "\n",
    "# get initial data where forecasts beat reference\n",
    "BSS_Ref = BS_EPEs['Sign_Ref'].sel(Method=['EPEs_Direct', 'HalfYear_Patt'])>0.9\n",
    "BSS_Ref = BSS_Ref.where(BSS_Ref)\n",
    "\n",
    "# for indirect forecasts mask also based on the boostrapping of perfect knowledge of patterns\n",
    "BSS_Ref_Indir = BSS_Ref.sel(Method='HalfYear_Patt').where(BSS_Ref_Mask_PerfectForecast).reset_coords(drop=True)\n",
    "BSS_Ref_Dir = BSS_Ref.sel(Method='EPEs_Direct').reset_coords(drop=True)\n",
    "BSS_Ref_All = xr.concat([BSS_Ref_Dir, BSS_Ref_Indir], dim=pd.Index(['EPEs_Direct', 'EPEs_Indirect'], name='Method'))\n",
    "\n",
    "# get last lead day that forecasts (indirect and direct) beat reference (allow only 1 non-sign. gap between the steps)\n",
    "BSS_Ref_All_values = np.apply_along_axis(ffill_windowed, 1, BSS_Ref_All, 1)\n",
    "BSS_Ref_All[:] = BSS_Ref_All_values\n",
    "BSS_Ref_All = BSS_Ref_All.sel(leaddays=range(2, BSS_Ref_All.leaddays.max().values+1)) # don't use lead 1, in case ...\n",
    "BSS_Ref_All = BSS_Ref_All.cumsum('leaddays', skipna=False) # ... is np.nan (1 np.nan gap is allowed so this is fine)\n",
    "BSS_Ref = BSS_Ref_All.max('leaddays') + 1 # add 1, since the LeadDays start from 2nd day and not the 1st one\n",
    "\n",
    "# get locations where Indirect BSS has extended horizon compared to Direct BSS\n",
    "BSS_Ind_Max = BSS_Ref.sel(Method='EPEs_Indirect')\n",
    "BSS_Ind_Max = BSS_Ind_Max.where(BSS_Ind_Max>BSS_Ref.sel(Method='EPEs_Direct')).reset_coords(drop=True)\n",
    "\n",
    "# get first day that indirect forecasts beat the direct ones and the climatology\n",
    "BSS_Combo = BS_EPEs['Sign_Combo'].sel(Method='HalfYear_Patt')>0.9\n",
    "BSS_Combo = BSS_Combo.where(BSS_Combo & BSS_Ref_Mask_PerfectForecast)*BSS_Combo.leaddays \n",
    "BSS_Combo = BSS_Combo.min('leaddays').reset_coords(drop=True)\n",
    "BSS_Combo = BSS_Combo.where(BSS_Combo<=BSS_Ref.sel(Method='EPEs_Indirect').reset_coords(drop=True))\n",
    "BSS_Combo = xr.concat([BSS_Ind_Max, BSS_Combo], dim='aux').min('aux') # needed as for clim. sign. 1 nan gap allowed\n",
    "\n",
    "del(BSS_Ref_Mask_PerfectForecast, BSS_Ref_Indir, BSS_Ref_Dir, BSS_Ref_All, BSS_Ref_All_values, BSS_Ind_Max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Fig9_type(perc_used=95):\n",
    "    \n",
    "    BSS_horizon = BSS_Ref.sel(percentile=perc_used).reset_coords(drop=True)\n",
    "    Vals_used = np.array(list(Vals_used_general)) # this is needed, otherwise Vals_used_general changes as well\n",
    "    max_lead = int(BSS_horizon.max().values)\n",
    "    if max_lead > Vals_used[-1]: Vals_used[-1] = max_lead\n",
    "    \n",
    "    fig, ax_all = plt.subplots(2, 2, figsize=(18/2.54, 12/2.54), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    ax_all = ax_all.flatten()\n",
    "    for i, ax in enumerate(ax_all[:2]):\n",
    "\n",
    "        data_mesh = BSS_horizon.isel(Method=i).values\n",
    "        ax.pcolor(X_all, Y_all, data_mesh, transform=ccrs.PlateCarree(), \n",
    "                  norm=BoundaryNorm(Vals_used, len(Cols_used)), cmap=ListedColormap(Cols_used)) \n",
    "\n",
    "        aux_title = ['direct', 'indirect']\n",
    "        ax.set_title(f\"({['a', 'b'][i]}) Forecasting horizon (in days) with {aux_title[i]} forecasts\", \n",
    "                     pad=4, size=8, loc='left')\n",
    "\n",
    "        # get the values so that the statistics are created and plotted on the colorbar\n",
    "        AllData = data_mesh.flatten()[~np.isnan(data_mesh.flatten())]     \n",
    "        Counts = pd.DataFrame({'Bins': [f'{i}~{j-1}' for i, j in zip(Vals_used[:-1], Vals_used[1:])], \n",
    "                               'Percentages': np.nan})\n",
    "        Counts.iloc[-1, 0] = f'{Vals_used[-2]}~{Vals_used[-1]}'\n",
    "\n",
    "        for i_bin in range(len(Counts)):\n",
    "            if i_bin==len(Counts)-1:\n",
    "                i_counts = sum((AllData >= Vals_used[i_bin]) & (AllData <= Vals_used[i_bin+1]))\n",
    "            else:\n",
    "                i_counts = sum((AllData >= Vals_used[i_bin]) & (AllData < Vals_used[i_bin+1]))\n",
    "            Counts.iloc[i_bin, 1] = np.round(i_counts/len(data_mesh.flatten())*100, 2).astype(str)\n",
    "\n",
    "        ax_sub = plot_discrete_bar_inset(col_lims=np.arange(len(Vals_used)), col_used=Cols_used, col_text='white',\n",
    "                                         data_used=Counts.Percentages.values, loc=8, width='100%', height='15%',\n",
    "                                         brdpad=-3, cat_names=Counts.Bins.values, bar_text_size=6.5, ax=ax,\n",
    "                                         xlabel='Percentage of grid cells (%)')\n",
    "\n",
    "    HorizonDif = BSS_horizon.fillna(0).diff('Method').values[0, ...]\n",
    "    MaxDif = int(np.abs(HorizonDif).max())\n",
    "    Colors_used = sns.color_palette('YlOrRd_r', n_colors=4) + ['white'] + sns.color_palette('GnBu', n_colors=4)\n",
    "    Colors_limits = [-10, -6, -4, -2, 0, 1, 3, 5, 7, 10]\n",
    "    if MaxDif>max(Colors_limits):\n",
    "        Colors_limits[0] = -MaxDif\n",
    "        Colors_limits[-1] = MaxDif\n",
    "\n",
    "    ax_all[2].pcolor(X_all, Y_all, HorizonDif, transform=ccrs.PlateCarree(), \n",
    "                     norm=BoundaryNorm(Colors_limits, len(Colors_used)), cmap=ListedColormap(Colors_used)) \n",
    "    ax_all[2].set_title('(c) Indirect-direct forecasting horizon difference (in days)', pad=4, size=8, loc='left')\n",
    "\n",
    "    AllData = HorizonDif.flatten()  \n",
    "    Counts = pd.DataFrame({'Bins': [f'{i}~{j-1}' for i, j in zip(Colors_limits[:-1], Colors_limits[1:])], \n",
    "                           'Percentages': np.nan})\n",
    "    Counts.iloc[-1, 0] = f'{Colors_limits[-2]}~{Colors_limits[-1]}'\n",
    "    Counts.iloc[4,0] = '0'\n",
    "\n",
    "    for i_bin in range(len(Counts)):\n",
    "        if i_bin==len(Counts)-1:\n",
    "            i_counts = sum((AllData >= Colors_limits[i_bin]) & (AllData <= Colors_limits[i_bin+1]))\n",
    "        else:\n",
    "            i_counts = sum((AllData >= Colors_limits[i_bin]) & (AllData < Colors_limits[i_bin+1]))\n",
    "        Counts.iloc[i_bin, 1] = np.round(i_counts/len(data_mesh.flatten())*100, 2).astype(str)\n",
    "\n",
    "    ax_sub = plot_discrete_bar_inset(col_lims=np.arange(len(Colors_limits)), col_used=Colors_used, col_text='black',  \n",
    "                                     data_used=Counts.Percentages.values, loc=8, width='100%', height='15%', \n",
    "                                     brdpad=-3, cat_names=Counts.Bins.values, bar_text_size=6.5, ax=ax_all[2],\n",
    "                                     xlabel='Percentage of grid cells (%)')\n",
    "\n",
    "    MinFrcst = BSS_Combo.sel(percentile=perc_used).values\n",
    "    MinFrcst_max = int(MinFrcst[~np.isnan(MinFrcst)].max())\n",
    "    Colors_limits = np.array([0, 6, 8, 10, 12, 15]) # np.arange(0, 15, 2)\n",
    "    Colors_used = sns.color_palette('Purples_r', n_colors=len(Colors_limits))[:-1]\n",
    "    if MinFrcst_max>max(Colors_limits):\n",
    "        Colors_limits[-1] = MinFrcst_max\n",
    "\n",
    "    ax_all[3].pcolor(X_all, Y_all, MinFrcst, transform=ccrs.PlateCarree(), \n",
    "                     norm=BoundaryNorm(Colors_limits, len(Colors_used)), cmap=ListedColormap(Colors_used)) \n",
    "    ax_all[3].set_title('(d) First lead day when indirect forecasts beat direct one', pad=4, size=8, loc='left')\n",
    "\n",
    "    AllData = MinFrcst.flatten()[~np.isnan(MinFrcst.flatten())]  \n",
    "    Counts = pd.DataFrame({'Bins': [f'{i}~{j-1}' for i, j in zip(Colors_limits[:-1], Colors_limits[1:])], \n",
    "                           'Percentages': np.nan})\n",
    "    Counts.iloc[-1, 0] = f'{Colors_limits[-2]}~{Colors_limits[-1]}'\n",
    "\n",
    "    for i_bin in range(len(Counts)):\n",
    "        if i_bin==len(Counts)-1:\n",
    "            i_counts = sum((AllData >= Colors_limits[i_bin]) & (AllData <= Colors_limits[i_bin+1]))\n",
    "        else:\n",
    "            i_counts = sum((AllData >= Colors_limits[i_bin]) & (AllData < Colors_limits[i_bin+1]))\n",
    "        Counts.iloc[i_bin, 1] = np.round(i_counts/MinFrcst.size*100, 2).astype(str)\n",
    "\n",
    "    ax_sub = plot_discrete_bar_inset(col_lims=np.arange(len(Colors_limits)), col_used=Colors_used, col_text='black',  \n",
    "                                     data_used=Counts.Percentages.values, loc=8, width='100%', height='15%', \n",
    "                                     brdpad=-3, cat_names=Counts.Bins.values, bar_text_size=6.5, ax=ax_all[3],\n",
    "                                     xlabel='Percentage of grid cells (%)')\n",
    "\n",
    "    for ax in ax_all:\n",
    "        ax.coastlines(resolution='110m', linewidth=.75, color='black')\n",
    "        ax.set_extent([X_min, X_max, Y_min, Y_max], crs=ccrs.PlateCarree())\n",
    "\n",
    "    plt.subplots_adjust(left=0.02, bottom=0.05, right=.98, top=1, wspace=0.05, hspace=0.05)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_perc in [90, 95, 99]:\n",
    "    Fig9 = Fig9_type(perc_used=i_perc)\n",
    "    Fig9.savefig(output_dir+f'Pdf/Fig9_{i_perc}.pdf')\n",
    "    Fig9.savefig(output_dir+f'Png/Fig9_{i_perc}.png', dpi=600, facecolor=Fig9.get_facecolor())\n",
    "    if i_perc!=95: plt.close()\n",
    "    \n",
    "del(i_perc, Fig9, Fig9_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphicalAbstract(perc_used=95):\n",
    "    \n",
    "    BSS_horizon = BSS_Ref.sel(percentile=perc_used).reset_coords(drop=True)\n",
    "    Vals_used = np.array(list(Vals_used_general)) # this is needed, otherwise Vals_used_general changes as well\n",
    "    max_lead = int(BSS_horizon.max().values)\n",
    "    if max_lead > Vals_used[-1]: Vals_used[-1] = max_lead\n",
    "    \n",
    "    fig, ax_all = plt.subplots(2, 1, figsize=(5/2.54, 5.5/2.54), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    ax_all = ax_all.flatten()\n",
    "    \n",
    "    data_mesh = BSS_horizon.sel(Method='EPEs_Indirect').values\n",
    "    ax_all[0].pcolor(X_all, Y_all, data_mesh, transform=ccrs.PlateCarree(), \n",
    "                     norm=BoundaryNorm(Vals_used, len(Cols_used)), cmap=ListedColormap(Cols_used)) \n",
    "\n",
    "    ax_all[0].set_title(\"Forecasting horizon (in days) with indirect forecasts\", pad=2, size=5, loc='left')\n",
    "\n",
    "    # get the values so that the statistics are created and plotted on the colorbar\n",
    "    AllData = data_mesh.flatten()[~np.isnan(data_mesh.flatten())]     \n",
    "    Counts = pd.DataFrame({'Bins': [f'{i}~{j-1}' for i, j in zip(Vals_used[:-1], Vals_used[1:])], \n",
    "                           'Percentages': np.nan})\n",
    "    Counts.iloc[-1, 0] = f'{Vals_used[-2]}~{Vals_used[-1]}'\n",
    "\n",
    "    for i_bin in range(len(Counts)):\n",
    "        if i_bin==len(Counts)-1:\n",
    "            i_counts = sum((AllData >= Vals_used[i_bin]) & (AllData <= Vals_used[i_bin+1]))\n",
    "        else:\n",
    "            i_counts = sum((AllData >= Vals_used[i_bin]) & (AllData < Vals_used[i_bin+1]))\n",
    "        Counts.iloc[i_bin, 1] = np.round(i_counts/len(data_mesh.flatten())*100, 2).astype(str)\n",
    "\n",
    "    ax_sub = plot_discrete_bar_inset(col_lims=np.arange(len(Vals_used)), col_used=Cols_used, col_text='white',\n",
    "                                     data_used=Counts.Percentages.values, loc=8, width='100%', height='15%',\n",
    "                                     brdpad=-1.5, cat_names=Counts.Bins.values, bar_text_size=4.5, xlabel='',\n",
    "                                     ax=ax_all[0])\n",
    "    ax_sub.set_xticks([])\n",
    "    ax_sub.set_xlabel('')\n",
    "    [i.set_linewidth(0.1) for i in ax_sub.spines.values()]\n",
    "\n",
    "    \n",
    "    HorizonDif = BSS_horizon.fillna(0).diff('Method').values[0, ...]\n",
    "    MaxDif = int(np.abs(HorizonDif).max())\n",
    "    Colors_used = sns.color_palette('YlOrRd_r', n_colors=4) + ['white'] + sns.color_palette('GnBu', n_colors=4)\n",
    "    Colors_limits = [-10, -6, -4, -2, 0, 1, 3, 5, 7, 10]\n",
    "    if MaxDif>max(Colors_limits):\n",
    "        Colors_limits[0] = -MaxDif\n",
    "        Colors_limits[-1] = MaxDif\n",
    "\n",
    "    ax_all[1].pcolor(X_all, Y_all, HorizonDif, transform=ccrs.PlateCarree(), \n",
    "                     norm=BoundaryNorm(Colors_limits, len(Colors_used)), cmap=ListedColormap(Colors_used)) \n",
    "    ax_all[1].set_title('Indirect-direct forecasting horizon difference (in days)', pad=2, size=5, loc='left')\n",
    "\n",
    "    AllData = HorizonDif.flatten()  \n",
    "    Counts = pd.DataFrame({'Bins': [f'{i}~{j-1}' for i, j in zip(Colors_limits[:-1], Colors_limits[1:])], \n",
    "                           'Percentages': np.nan})\n",
    "    Counts.iloc[-1, 0] = f'{Colors_limits[-2]}~{Colors_limits[-1]}'\n",
    "    Counts.iloc[4,0] = '0'\n",
    "\n",
    "    for i_bin in range(len(Counts)):\n",
    "        if i_bin==len(Counts)-1:\n",
    "            i_counts = sum((AllData >= Colors_limits[i_bin]) & (AllData <= Colors_limits[i_bin+1]))\n",
    "        else:\n",
    "            i_counts = sum((AllData >= Colors_limits[i_bin]) & (AllData < Colors_limits[i_bin+1]))\n",
    "        Counts.iloc[i_bin, 1] = np.round(i_counts/len(data_mesh.flatten())*100, 2).astype(str)\n",
    "\n",
    "    ax_sub = plot_discrete_bar_inset(col_lims=np.arange(len(Colors_limits)), col_used=Colors_used, col_text='black',  \n",
    "                                     data_used=Counts.Percentages.values, loc=8, width='100%', height='15%', \n",
    "                                     brdpad=-1.5, cat_names=Counts.Bins.values, bar_text_size=4.5, xlabel='',\n",
    "                                     ax=ax_all[1])\n",
    "    ax_sub.set_xticks([])\n",
    "    ax_sub.set_xlabel('')\n",
    "    [i.set_linewidth(0.1) for i in ax_sub.spines.values()]\n",
    "\n",
    "    \n",
    "    for ax in ax_all:\n",
    "        ax.coastlines(resolution='110m', linewidth=.5, color='black')\n",
    "        ax.set_extent([X.min(), X.max(), Y.min(), Y.max()], crs=ccrs.PlateCarree())\n",
    "\n",
    "    plt.subplots_adjust(left=0.02, bottom=0.02, right=.98, top=1, hspace=.0, wspace=0.)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "GraphAb = GraphicalAbstract()\n",
    "GraphAb.savefig(output_dir+'Pdf/GraphAb.pdf', dpi=600)\n",
    "GraphAb.savefig(output_dir+'Png/GraphAb.png', dpi=600, facecolor=GraphAb.get_facecolor())\n",
    "del(GraphAb, GraphicalAbstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(Aggregated, AggregatedData, BSS_Combo, BSS_Ref, BS_EPEs, Cl_cols_used, Cl_vals_used, Cols_used,\n",
    "    Vals_used_general, Weights, X, Y, X_all, Y_all, btlw, ffill_windowed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_EPEs = xr.open_dataarray(input_dir+f'ForecastsEPEs_Analysis/EV_leaddays.nc')\n",
    "Weights = np.cos(np.radians(EV_EPEs.latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ref = EV_EPEs.sel(Method=['Clim_DayMonth', 'Clim_Seasonal']).max('Method').assign_coords({'Method': 'Reference'})\n",
    "EV_EPEs = xr.concat([EV_EPEs.sel(Method=['Direct', 'Indirect']), Ref], dim='Method')\n",
    "del(Ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "AggregatedData = [aggregated_stats(EV_EPEs, i_val) for i_val in Areas.values()]\n",
    "AggregatedData = xr.concat(AggregatedData, dim=pd.Index(list(Areas.keys()), name='Area'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_Max = AggregatedData.max('Method')\n",
    "EV_Max.name = 'Max'\n",
    "EV_ArgMax = AggregatedData.argmax('Method')\n",
    "EV_ArgMax.name = 'ArgMax'\n",
    "EV_Max = xr.merge([EV_Max, EV_ArgMax])\n",
    "del(EV_ArgMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_Max_DF = EV_Max.to_dataframe().reset_index()\n",
    "EV_Max_DF = EV_Max_DF.sort_values(['Area', 'percentile', 'leaddays', 'cost_ratio'])\n",
    "\n",
    "EV_Max_DF = EV_Max_DF.query('Max>0')\n",
    "EV_Max_DF.index = range(len(EV_Max_DF))\n",
    "\n",
    "# create extra rows when the argmax changes for the same lead time. These extra rows will be located in the half \n",
    "# distance of the previous and next, and have as argmax once the previous and once the next argmax, so consecutive\n",
    "# lines without gaps, and with the color of the relevant method, can be constructed\n",
    "EV_Max_DF['ArgMax2'] = EV_Max_DF['ArgMax'].shift()\n",
    "EV_Max_DF.loc[0, 'ArgMax2'] = EV_Max_DF.loc[0, 'ArgMax']\n",
    "\n",
    "mask = (EV_Max_DF['ArgMax2']!=EV_Max_DF['ArgMax']) & (EV_Max_DF['leaddays']==EV_Max_DF['leaddays'].shift())\n",
    "df_change = EV_Max_DF[mask].copy(deep=True)\n",
    "df_change[['cost_ratio', 'Max', 'ArgMax', 'ArgMax2']] = np.nan\n",
    "df_change = df_change.set_index(df_change.index-0.5)\n",
    "for i_ind in df_change.index:\n",
    "    values_used = EV_Max_DF.loc[[np.floor(i_ind), np.ceil(i_ind)], ['cost_ratio', 'Max']].mean()\n",
    "    df_change.loc[i_ind, ['cost_ratio', 'Max']] = values_used\n",
    "    \n",
    "EV_Max_DF = pd.concat([EV_Max_DF, df_change, df_change]).sort_index().drop('ArgMax2', 1)\n",
    "EV_Max_DF.ArgMax = EV_Max_DF.ArgMax.fillna(method='ffill', limit=1)\n",
    "EV_Max_DF.ArgMax = EV_Max_DF.ArgMax.fillna(method='bfill', limit=1)\n",
    "del(i_ind, values_used, mask, df_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fig10_type(perc_used=95, lead_times_used=[1, 5, 7, 14]):\n",
    "    \n",
    "    DF_used = EV_Max_DF.query('percentile==@perc_used and leaddays==@lead_times_used')\n",
    "    Max = np.ceil(DF_used.Max.max()*10)/10\n",
    "    fig, ax_all = plt.subplots(2, 3, figsize=(18/2.54, 9/2.54))\n",
    "    ax_all = ax_all.flatten()\n",
    "    \n",
    "    for i, i_area in enumerate(Areas):\n",
    "        for j, i_lead in enumerate(lead_times_used):\n",
    "            DF_new = DF_used.query('Area==@i_area and leaddays==@i_lead')\n",
    "            DF_new = DF_new.pivot_table(values='Max', index='cost_ratio', columns='ArgMax')\n",
    "            DF_new = DF_new.reindex(DF_new.columns.union(np.arange(len(EV_EPEs.Method)).astype(float)), axis=1)\n",
    "            DF_new.columns = pd.Index(EV_EPEs.Method, name='Method')\n",
    "            if j>0:\n",
    "                DF_new.plot(linewidth=2, color=sns.color_palette(n_colors=4), ax=ax_all[i], legend=False)\n",
    "            else:\n",
    "                DF_new.plot(linewidth=2, color=sns.color_palette(n_colors=4), ax=ax_all[i], legend=True)\n",
    "                if i==0: [line.set_linewidth(2) for line in ax_all[i].legend().get_lines()]\n",
    "        \n",
    "        if i!=0: ax_all[i].legend().remove()\n",
    "        \n",
    "        ax_all[i].set_xlabel('Cost-Loss ratio')\n",
    "        ax_all[i].set_ylim(0, Max)\n",
    "        ax_all[i].set_xlim(0, 1)\n",
    "        ax_all[i].set_ylabel('Vmax')\n",
    "        ax_all[i].set_title(f\"({['a', 'b', 'c', 'd', 'e', 'f'][i]}) {i_area}\", pad=4, loc='left', size=8)\n",
    "        ax_all[i].xaxis.set_tick_params(width=.25, length=2) # modify x-axis ticks\n",
    "        ax_all[i].yaxis.set_tick_params(width=.25, length=2) # modify y-axis ticks\n",
    "        \n",
    "        if i>0:\n",
    "            ax_sub = inset_axes(ax_all[i], loc=1, width='60%', height='40%',\n",
    "                                axes_class=cartopy.mpl.geoaxes.GeoAxes, \n",
    "                                axes_kwargs=dict(map_projection=ccrs.PlateCarree()))\n",
    "            ax_sub.coastlines(resolution='110m', linewidth=.5, color='black')\n",
    "            ax_sub.set_extent([X_min, X_max, Y_min, Y_max], crs=ccrs.PlateCarree())\n",
    "            x_min, x_max, y_min, y_max = Areas[i_area]\n",
    "            rect = plt.Rectangle((x_min, y_min),x_max-x_min, y_max-y_min, fill=False, color='red', linewidth=.75) \n",
    "            ax_sub.add_patch(rect) # add rectangle with the actual area used for the Precipitation analysis\n",
    "\n",
    "            \n",
    "    plt.subplots_adjust(left=0.07, bottom=0.12, right=.99, top=.93, wspace=0.3, hspace=0.5)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_perc in [90, 95, 99]:\n",
    "    Fig10 = Fig10_type(perc_used=i_perc, lead_times_used=[7, 11, 17])\n",
    "    Fig10.savefig(output_dir+f'Pdf/Fig10_{i_perc}.pdf')\n",
    "    Fig10.savefig(output_dir+f'Png/Fig10_{i_perc}.png', dpi=600, facecolor=Fig10.get_facecolor())\n",
    "    if i_perc!=95: plt.close()\n",
    "    \n",
    "del(i_perc, Fig10, Fig10_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FigS10_type_supl(perc_used=95, lead_times_used=11):\n",
    "    \n",
    "    DF_used = AggregatedData.sel(percentile=perc_used, leaddays=lead_times_used)\n",
    "    \n",
    "    Max = np.ceil(DF_used.values.max()*10)/10\n",
    "    fig, ax_all = plt.subplots(2, 3, figsize=(18/2.54, 9/2.54))\n",
    "    ax_all = ax_all.flatten()\n",
    "    \n",
    "    for i, i_area in enumerate(Areas):\n",
    "        DF_new = DF_used.sel(Area=i_area).to_dataframe('Max').reset_index().query('Max>0')\n",
    "        sns.lineplot(data=DF_new, x='cost_ratio', y='Max', hue='Method', linewidth=2, ax=ax_all[i])\n",
    "\n",
    "        if i!=0: ax_all[i].legend().remove()\n",
    "        if i==0: [line.set_linewidth(2) for line in ax_all[i].legend().get_lines()]\n",
    "    \n",
    "        ax_all[i].set_xlabel('Cost-Loss ratio')\n",
    "        ax_all[i].set_ylim(0, Max)\n",
    "        ax_all[i].set_xlim(0, 1)\n",
    "        ax_all[i].set_ylabel('Vmax')\n",
    "        ax_all[i].set_title(f\"({['a', 'b', 'c', 'd', 'e', 'f'][i]}) {i_area}\", pad=4, loc='left', size=8)\n",
    "        ax_all[i].xaxis.set_tick_params(width=.25, length=2) # modify x-axis ticks\n",
    "        ax_all[i].yaxis.set_tick_params(width=.25, length=2) # modify y-axis ticks\n",
    "        \n",
    "        if i>0:\n",
    "            ax_sub = inset_axes(ax_all[i], loc=1, width='60%', height='40%', #bbox_to_anchor=(0, 1, 1, 1),\n",
    "                                axes_class=cartopy.mpl.geoaxes.GeoAxes, \n",
    "                                axes_kwargs=dict(map_projection=ccrs.PlateCarree()))\n",
    "            ax_sub.coastlines(resolution='110m', linewidth=.5, color='black')\n",
    "            ax_sub.set_extent([X_min, X_max, Y_min, Y_max], crs=ccrs.PlateCarree())\n",
    "            x_min, x_max, y_min, y_max = Areas[i_area]\n",
    "            rect = plt.Rectangle((x_min, y_min),x_max-x_min, y_max-y_min, fill=False, color='red',# linestyle='--',\n",
    "                                 linewidth=.75) \n",
    "            ax_sub.add_patch(rect) # add rectangle with the actual area used for the Precipitation analysis\n",
    "\n",
    "            \n",
    "    plt.subplots_adjust(left=0.07, bottom=0.12, right=.99, top=.93, wspace=0.3, hspace=0.5)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_perc in [95]:\n",
    "    for i_lead in [7]:\n",
    "        FigS10 = FigS10_type_supl(perc_used=i_perc, lead_times_used=i_lead)\n",
    "        FigS10.savefig(output_dir+f'Pdf/FigS10_{i_perc}_{i_lead}.pdf')\n",
    "        FigS10.savefig(output_dir+f'Png/FigS10_{i_perc}_{i_lead}.png', dpi=600, facecolor=FigS10.get_facecolor())\n",
    "        if i_perc!=95 or i_lead!=7: plt.close()\n",
    "    \n",
    "del(i_perc, i_lead, FigS10, FigS10_type_supl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(AggregatedData, EV_EPEs, EV_Max, EV_Max_DF, Weights, aggregated_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
